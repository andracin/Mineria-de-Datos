{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import io \n",
    "import requests\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TVE</th>\n",
       "      <th>COVM</th>\n",
       "      <th>COVP</th>\n",
       "      <th>EDUM</th>\n",
       "      <th>EDUP</th>\n",
       "      <th>MTRAB</th>\n",
       "      <th>PTRAB</th>\n",
       "      <th>#PCONV</th>\n",
       "      <th>PHERMANO</th>\n",
       "      <th>TPOBLACION</th>\n",
       "      <th>...</th>\n",
       "      <th>ET</th>\n",
       "      <th>LAPTOP</th>\n",
       "      <th>INTERNET</th>\n",
       "      <th>DEPOR</th>\n",
       "      <th>RSENTI</th>\n",
       "      <th>P1-16</th>\n",
       "      <th>P2-16</th>\n",
       "      <th>P3-16</th>\n",
       "      <th>P4</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TVE  COVM  COVP  EDUM  EDUP  MTRAB  PTRAB  #PCONV  PHERMANO  TPOBLACION  \\\n",
       "0    0     0     0     0     0      0      0       9         0           0   \n",
       "1    1     1     0     1     1      1      0       3         3           0   \n",
       "2    1     1     0     2     0      0      0       5         3           0   \n",
       "3    0     1     0     2     2      0      0       4         1           0   \n",
       "4    0     1     1     1     1      1      0       2         4           0   \n",
       "\n",
       "  ...  ET  LAPTOP  INTERNET  DEPOR  RSENTI  P1-16  P2-16  P3-16   P4   C  \n",
       "0 ...   0       0         0      0       0    2.9    3.4    3.4  3.6   A  \n",
       "1 ...   0       0         1      1       0    2.6    2.4    2.8  3.9   A  \n",
       "2 ...   0       1         1      0       1    3.1    3.4    3.5  3.9   A  \n",
       "3 ...   0       1         1      0       1    3.0    3.1    3.5  3.7   A  \n",
       "4 ...   0       0         0      0       1    2.7    2.9    2.1  3.1  BS  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds_ = pd.read_csv('F8N4P.csv', sep=';', na_values=\"?\", decimal=',')# se carga el cojunto de datos csv\n",
    "ds_ = pd.read_csv('F4P17.csv', sep=';', na_values=\"?\", decimal=',')# se carga el cojunto de datos csv\n",
    "\n",
    "#ds_ = pd.read_csv('F4NP17.csv', sep=';', na_values=\"?\", decimal=',')\n",
    "ds = ds_.dropna() # se elimina las filas/columnas con valores null\n",
    "# Convertir datos categoricos a numericos\n",
    "ds = ds.rename(columns = {ds.columns.values[21]:'C'}) # renombramos la ultima columna por \"C\" de clase\n",
    "#le = preprocessing.LabelEncoder() # Label encoder de sci-kit\n",
    "\n",
    "# Convertir datos categoricos a numericos\n",
    "tipos = ds.columns[0:21].to_series().groupby(ds.dtypes).groups\n",
    "ctext = tipos[np.dtype('object')]\n",
    "\n",
    "for c in ctext:\n",
    "     ds[c], _ = pd.factorize(ds[c])  \n",
    "\n",
    "#ds = ds.apply(le.fit_transform) # Convertimos los valores de object a numericos\n",
    "#ds.head() # se verifica el resultado de cargue de los dato\n",
    "##VAL = pd.read_csv('VAL.csv', sep=';', na_values=\"?\", decimal=',')\n",
    "##tipos = VAL.columns[0:23].to_series().groupby(VAL.dtypes).groups\n",
    "##ctext = tipos[np.dtype('object')]\n",
    "\n",
    "##for c in ctext:\n",
    "  ##   VAL[c], _ = pd.factorize(VAL[c])  \n",
    "\n",
    "ds.C.value_counts()\n",
    "ds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del ds['COVP']\n",
    "del ds['EDUM']\n",
    "del ds['LAPTOP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de clases conjunto train Counter({'BS': 60, 'B': 54, 'A': 40})\n",
      "Conteo de Clases conjunto test  Counter({'BS': 29, 'A': 19, 'B': 19})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=ds.drop('C', axis = 1)\n",
    "y=ds['C']\n",
    "from collections import Counter\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=1)\n",
    "df=pd.DataFrame(x_train)\n",
    "df['C']=y_train\n",
    "dt=pd.DataFrame(x_test)\n",
    "dt['C']=y_test\n",
    "print('Conteo de clases conjunto train {}'.format(Counter(y_train)))\n",
    "print('Conteo de Clases conjunto test  {}'.format(Counter(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy SVM Lineal C=10, gamma=10 ##################\n",
      "0.8805970149253731\n",
      "\n",
      "############## Confusion SVM Lineal C=10, gamma=10 ################\n",
      "[[17  0  2]\n",
      " [ 0 17  2]\n",
      " [ 3  1 25]]\n",
      "\n",
      "############## Metricas SVM Lineal C=10, gamma=10 ##################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.85      0.89      0.87        19\n",
      "           B       0.94      0.89      0.92        19\n",
      "          BS       0.86      0.86      0.86        29\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        67\n",
      "   macro avg       0.89      0.88      0.88        67\n",
      "weighted avg       0.88      0.88      0.88        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################### RBF SVM  C=10.0############################\n",
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "SVMrbf = svm.SVC(kernel='linear',C=10, gamma=10)\n",
    "SVMrbf.fit(xntrain, yntrain)\n",
    "#print(SVMrbf.predict(VAL))\n",
    "SVMrbf_predict = SVMrbf.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(metrics.accuracy_score(yntest, SVMrbf_predict))\n",
    "print(\"\\n############## Confusion SVM Lineal C=10, gamma=10 ################\")\n",
    "print(metrics.confusion_matrix(yntest, SVMrbf_predict))\n",
    "print(\"\\n############## Metricas SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(classification_report(yntest,SVMrbf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseLibSVM.fit of SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=10, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMrbf.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy KNN  K=4 ####################################\n",
      "0.5522388059701493\n",
      "\n",
      "############## Confusion KNN  K=4 #####################################\n",
      "[[ 9  1  9]\n",
      " [ 1 13  5]\n",
      " [ 2 12 15]]\n",
      "\n",
      "############## Metricas KNN  K=4 #####################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      0.47      0.58        19\n",
      "           B       0.50      0.68      0.58        19\n",
      "          BS       0.52      0.52      0.52        29\n",
      "\n",
      "   micro avg       0.55      0.55      0.55        67\n",
      "   macro avg       0.59      0.56      0.56        67\n",
      "weighted avg       0.58      0.55      0.55        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "##################  K-Vecinos más cercanos #####################\n",
    "################################################################\n",
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "n_neighbors = 4\n",
    "KNN = KNeighborsClassifier(n_neighbors)\n",
    "KNN.fit(xntrain, yntrain)\n",
    "KNN_predict = KNN.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy KNN  K=4 ####################################\")\n",
    "print(metrics.accuracy_score(yntest, KNN_predict))\n",
    "print(\"\\n############## Confusion KNN  K=4 #####################################\")\n",
    "print(metrics.confusion_matrix(yntest, KNN_predict))\n",
    "print(\"\\n############## Metricas KNN  K=4 #####################################\")\n",
    "print(classification_report(yntest,KNN_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2aedfb0f60e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0016\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclf_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    975\u001b[0m         \"\"\"\n\u001b[0;32m    976\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m--> 977\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    322\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 914\u001b[1;33m                          multi_output=True)\n\u001b[0m\u001b[0;32m    915\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BS'"
     ]
    }
   ],
   "source": [
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf =clf = MLPClassifier(hidden_layer_sizes=(13,13,13,13,13,13,13,13,13,13) ,activation='relu',random_state=1, learning_rate_init=0.0016)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf_predict = clf.predict(x_test)\n",
    "\n",
    "print(\"\\n### Accuracy MLP capas ocultas 10 ,unidades ocultas 13 ######################\")\n",
    "print(metrics.accuracy_score(y_test, clf_predict))\n",
    "print(\"\\n### Confusion MLP capas ocultas 10 ,unidades ocultas 13 #####################\")\n",
    "print(metrics.confusion_matrix(y_test, clf_predict))\n",
    "print(\"\\n### Metricas MLP capas ocultas 10 ,unidades ocultas 13 #######################\")\n",
    "print(classification_report(y_test, clf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Balanceo de Datos usando Oversampling\"\n",
    "mejora la prediccion despues de este proceso pero hay que ajustarlo para que mejore con el categoria 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BS    89\n",
       "B     73\n",
       "A     59\n",
       "Name: C, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ = pd.read_csv('F8N4P.csv', sep=';', na_values=\"?\", decimal=',')# se carga el cojunto de datos csv\n",
    "ds = ds_.dropna() # se elimina las filas/columnas con valores null\n",
    "# Convertir datos categoricos a numericos\n",
    "ds = ds.rename(columns = {ds.columns.values[22]:'C'}) # renombramos la ultima columna por \"C\" de clase\n",
    "#le = preprocessing.LabelEncoder() # Label encoder de sci-kit\n",
    "\n",
    "# Convertir datos categoricos a numericos\n",
    "tipos = ds.columns[0:21].to_series().groupby(ds.dtypes).groups\n",
    "ctext = tipos[np.dtype('object')]\n",
    "\n",
    "for c in ctext:\n",
    "     ds[c], _ = pd.factorize(ds[c])  \n",
    "\n",
    "#ds = ds.apply(le.fit_transform) # Convertimos los valores de object a numericos\n",
    "#ds.head() # se verifica el resultado de cargue de los dato\n",
    "\n",
    "ds.C.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del ds['COVP']\n",
    "del ds['EDUM']\n",
    "del ds['LAPTOP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     89\n",
       "BS    89\n",
       "B     89\n",
       "Name: C, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# separar las clases entre mayoritaria y minoritaria \n",
    "ds_majority = ds[ds.C == \"BS\"]\n",
    "ds_minority1 = ds[ds.C == \"B\"]\n",
    "ds_minority2 = ds[ds.C == \"A\"] \n",
    "# sobre muestrear las clases minoritarias\n",
    "ds_minority_upsampled1 = resample(ds_minority1, \n",
    "                                 replace=True,     # Muestreo con remplazo\n",
    "                                 n_samples=89,    # cantidad de muestras a igualar \n",
    "                                 random_state=123) \n",
    "\n",
    "ds_minority_upsampled2 = resample(ds_minority2, \n",
    "                                 replace=True,     # Muestreo con remplazo\n",
    "                                 n_samples=89,    # cantidad de muestras a igualar\n",
    "                                 random_state=123) \n",
    "#ds_minority_upsampled3 = resample(ds_minority3, \n",
    " #                                replace=True,     # Muestreo con remplazo\n",
    "   #                              n_samples=2713,    # cantidad de muestras a igualar\n",
    "  #                               random_state=123) \n",
    "\n",
    "# concaternar la clase mayoritaria con la clases minoritarias creadas recientemente\n",
    "ds_upsampled = pd.concat([ds_majority, ds_minority_upsampled1,ds_minority_upsampled2])\n",
    " \n",
    "# imprimir el numero de muestras por clase\n",
    "ds_upsampled.C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de clases conjunto train Counter({'A': 63, 'B': 62, 'BS': 61})\n",
      "Conteo de Clases conjunto test  Counter({'BS': 28, 'B': 27, 'A': 26})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=ds.drop('C', axis = 1)\n",
    "y=ds['C']\n",
    "from collections import Counter\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=1)\n",
    "df=pd.DataFrame(x_train)\n",
    "df['C']=y_train\n",
    "dt=pd.DataFrame(x_test)\n",
    "dt['C']=y_test\n",
    "print('Conteo de clases conjunto train {}'.format(Counter(y_train)))\n",
    "print('Conteo de Clases conjunto test  {}'.format(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy SVM Lineal C=10, gamma=10 ##################\n",
      "0.8888888888888888\n",
      "\n",
      "############## Confusion SVM Lineal C=10, gamma=10 ################\n",
      "[[26  0  0]\n",
      " [ 0 25  2]\n",
      " [ 3  4 21]]\n",
      "\n",
      "############## Metricas SVM Lineal C=10, gamma=10 ##################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.90      1.00      0.95        26\n",
      "           B       0.86      0.93      0.89        27\n",
      "          BS       0.91      0.75      0.82        28\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        81\n",
      "   macro avg       0.89      0.89      0.89        81\n",
      "weighted avg       0.89      0.89      0.89        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################### RBF SVM  C=10.0############################\n",
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "SVMrbf = svm.SVC(kernel='linear',C=10, gamma=10)\n",
    "SVMrbf.fit(xntrain, yntrain)\n",
    "\n",
    "SVMrbf_predict = SVMrbf.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(metrics.accuracy_score(yntest, SVMrbf_predict))\n",
    "print(\"\\n############## Confusion SVM Lineal C=10, gamma=10 ################\")\n",
    "print(metrics.confusion_matrix(yntest, SVMrbf_predict))\n",
    "print(\"\\n############## Metricas SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(classification_report(yntest,SVMrbf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy KNN  K=4 ####################################\n",
      "0.4567901234567901\n",
      "\n",
      "############## Confusion KNN  K=4 #####################################\n",
      "[[16  2  8]\n",
      " [ 3 13 11]\n",
      " [ 8 12  8]]\n",
      "\n",
      "############## Metricas KNN  K=4 #####################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.59      0.62      0.60        26\n",
      "           B       0.48      0.48      0.48        27\n",
      "          BS       0.30      0.29      0.29        28\n",
      "\n",
      "   micro avg       0.46      0.46      0.46        81\n",
      "   macro avg       0.46      0.46      0.46        81\n",
      "weighted avg       0.45      0.46      0.45        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "##################  K-Vecinos más cercanos #####################\n",
    "################################################################\n",
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "n_neighbors = 4\n",
    "KNN = KNeighborsClassifier(n_neighbors)\n",
    "KNN.fit(xntrain, yntrain)\n",
    "KNN_predict = KNN.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy KNN  K=4 ####################################\")\n",
    "print(metrics.accuracy_score(yntest, KNN_predict))\n",
    "print(\"\\n############## Confusion KNN  K=4 #####################################\")\n",
    "print(metrics.confusion_matrix(yntest, KNN_predict))\n",
    "print(\"\\n############## Metricas KNN  K=4 #####################################\")\n",
    "print(classification_report(yntest,KNN_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy MLP layer hidden 10 ,unidades 64 #########\n",
      "0.8024691358024691\n",
      "\n",
      "############## Confusion MLP layer hidden 10 ,unidades 64 #########\n",
      "[[25  0  1]\n",
      " [ 0 23  4]\n",
      " [ 3  8 17]]\n",
      "\n",
      "############## Metricas MLP layer hidden 10 ,unidades 64 ##########\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.89      0.96      0.93        26\n",
      "           B       0.74      0.85      0.79        27\n",
      "          BS       0.77      0.61      0.68        28\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        81\n",
      "   macro avg       0.80      0.81      0.80        81\n",
      "weighted avg       0.80      0.80      0.80        81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(64,64,64,64,64,64,64,64,64,64), activation='relu',\n",
    "                    random_state=1, learning_rate_init=0.00016)\n",
    "\n",
    "clf.fit(xntrain, yntrain)\n",
    "\n",
    "clf_predict2 = clf.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy MLP layer hidden 10 ,unidades 64 #########\")\n",
    "print(metrics.accuracy_score(yntest, clf_predict2))\n",
    "print(\"\\n############## Confusion MLP layer hidden 10 ,unidades 64 #########\")\n",
    "print(metrics.confusion_matrix(yntest, clf_predict2))\n",
    "print(\"\\n############## Metricas MLP layer hidden 10 ,unidades 64 ##########\")\n",
    "print(classification_report(yntest,clf_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Balanceo de Datos usando undersampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BS    89\n",
       "B     73\n",
       "A     59\n",
       "Name: C, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ = pd.read_csv('F8N4P.csv', sep=';', na_values=\"?\", decimal=',')# se carga el cojunto de datos csv\n",
    "ds = ds_.dropna() # se elimina las filas/columnas con valores null\n",
    "# Convertir datos categoricos a numericos\n",
    "ds = ds.rename(columns = {ds.columns.values[22]:'C'}) # renombramos la ultima columna por \"C\" de clase\n",
    "#le = preprocessing.LabelEncoder() # Label encoder de sci-kit\n",
    "\n",
    "# Convertir datos categoricos a numericos\n",
    "tipos = ds.columns[0:21].to_series().groupby(ds.dtypes).groups\n",
    "ctext = tipos[np.dtype('object')]\n",
    "\n",
    "for c in ctext:\n",
    "     ds[c], _ = pd.factorize(ds[c])  \n",
    "\n",
    "#ds = ds.apply(le.fit_transform) # Convertimos los valores de object a numericos\n",
    "#ds.head() # se verifica el resultado de cargue de los dato\n",
    "\n",
    "ds.C.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del ds['COVP']\n",
    "del ds['EDUM']\n",
    "del ds['LAPTOP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     59\n",
       "BS    59\n",
       "B     59\n",
       "Name: C, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# separar las clases entre mayoritaria y minoritaria \n",
    "ds_majority = ds[ds.C == \"BS\"]\n",
    "ds_minorityd1 = ds[ds.C == \"B\"]\n",
    "ds_minorityd2 = ds[ds.C == \"A\"] \n",
    "#ds_minorityd3 = ds[ds.C == 3]\n",
    "# sobre muestrear las clases minoritarias\n",
    "ds_majority_downsampled = resample(ds_majority, \n",
    "                                 replace=False,     # Muestreo sin remplaso\n",
    "                                 n_samples=59,    # cantidad de muestra a igualar\n",
    "                                 random_state=123) \n",
    "\n",
    "ds_majority_downsampled1 = resample(ds_minorityd1, \n",
    "                                 replace=False,     # Muestreo sin remplaso\n",
    "                                 n_samples=59,    # cantidad de muestra a igualar\n",
    "                                 random_state=123) \n",
    "\n",
    "\n",
    "\n",
    "# concaternar la clase mayoritaria con la clases minoritarias creadas recientemente\n",
    "ds_downsampled = pd.concat([ds_majority_downsampled,ds_majority_downsampled1, ds_minorityd2 ])\n",
    " \n",
    "# imprimir el numero de muestras por clase\n",
    "ds_downsampled.C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de clases conjunto train Counter({'A': 48, 'B': 39, 'BS': 36})\n",
      "Conteo de Clases conjunto test  Counter({'BS': 23, 'B': 20, 'A': 11})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=ds.drop('C', axis = 1)\n",
    "y=ds['C']\n",
    "from collections import Counter\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=1)\n",
    "df=pd.DataFrame(x_train)\n",
    "df['C']=y_train\n",
    "dt=pd.DataFrame(x_test)\n",
    "dt['C']=y_test\n",
    "print('Conteo de clases conjunto train {}'.format(Counter(y_train)))\n",
    "print('Conteo de Clases conjunto test  {}'.format(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy SVM Lineal C=10, gamma=10 ##################\n",
      "0.7407407407407407\n",
      "\n",
      "############## Confusion SVM Lineal C=10, gamma=10 ################\n",
      "[[ 9  0  2]\n",
      " [ 1 14  5]\n",
      " [ 4  2 17]]\n",
      "\n",
      "############## Metricas SVM Lineal C=10, gamma=10 ##################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.64      0.82      0.72        11\n",
      "           B       0.88      0.70      0.78        20\n",
      "          BS       0.71      0.74      0.72        23\n",
      "\n",
      "   micro avg       0.74      0.74      0.74        54\n",
      "   macro avg       0.74      0.75      0.74        54\n",
      "weighted avg       0.76      0.74      0.74        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################### RBF SVM  C=10.0############################\n",
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "SVMrbf = svm.SVC(kernel='linear',C=10, gamma=10)\n",
    "SVMrbf.fit(xntrain, yntrain)\n",
    "\n",
    "SVMrbf_predict = SVMrbf.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(metrics.accuracy_score(yntest, SVMrbf_predict))\n",
    "print(\"\\n############## Confusion SVM Lineal C=10, gamma=10 ################\")\n",
    "print(metrics.confusion_matrix(yntest, SVMrbf_predict))\n",
    "print(\"\\n############## Metricas SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(classification_report(yntest,SVMrbf_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy KNN  K=4 ####################################\n",
      "0.4074074074074074\n",
      "\n",
      "############## Confusion KNN  K=4 #####################################\n",
      "[[ 9  1  1]\n",
      " [ 5 11  4]\n",
      " [ 9 12  2]]\n",
      "\n",
      "############## Metricas KNN  K=4 #####################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.39      0.82      0.53        11\n",
      "           B       0.46      0.55      0.50        20\n",
      "          BS       0.29      0.09      0.13        23\n",
      "\n",
      "   micro avg       0.41      0.41      0.41        54\n",
      "   macro avg       0.38      0.49      0.39        54\n",
      "weighted avg       0.37      0.41      0.35        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "##################  K-Vecinos más cercanos #####################\n",
    "################################################################\n",
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "n_neighbors = 4\n",
    "KNN = KNeighborsClassifier(n_neighbors)\n",
    "KNN.fit(xntrain, yntrain)\n",
    "KNN_predict = KNN.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy KNN  K=4 ####################################\")\n",
    "print(metrics.accuracy_score(yntest, KNN_predict))\n",
    "print(\"\\n############## Confusion KNN  K=4 #####################################\")\n",
    "print(metrics.confusion_matrix(yntest, KNN_predict))\n",
    "print(\"\\n############## Metricas KNN  K=4 #####################################\")\n",
    "print(classification_report(yntest,KNN_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy MLP layer hidden 10 ,unidades 64 #########\n",
      "0.6296296296296297\n",
      "\n",
      "############## Confusion MLP layer hidden 10 ,unidades 64 #########\n",
      "[[ 7  1  3]\n",
      " [ 3 12  5]\n",
      " [ 5  3 15]]\n",
      "\n",
      "############## Metricas MLP layer hidden 10 ,unidades 64 ##########\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.47      0.64      0.54        11\n",
      "           B       0.75      0.60      0.67        20\n",
      "          BS       0.65      0.65      0.65        23\n",
      "\n",
      "   micro avg       0.63      0.63      0.63        54\n",
      "   macro avg       0.62      0.63      0.62        54\n",
      "weighted avg       0.65      0.63      0.63        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "xntrain =df.drop('C', axis = 1)\n",
    "yntrain = df['C']\n",
    "xntest =dt.drop('C', axis = 1)\n",
    "yntest = dt['C']\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(64,64,64,64,64,64,64,64,64,64), activation='relu',\n",
    "                    random_state=1, learning_rate_init=0.00016)\n",
    "\n",
    "clf.fit(xntrain, yntrain)\n",
    "\n",
    "clf_predict2 = clf.predict(xntest)\n",
    "\n",
    "print(\"\\n############## Accuracy MLP layer hidden 10 ,unidades 64 #########\")\n",
    "print(metrics.accuracy_score(yntest, clf_predict2))\n",
    "print(\"\\n############## Confusion MLP layer hidden 10 ,unidades 64 #########\")\n",
    "print(metrics.confusion_matrix(yntest, clf_predict2))\n",
    "print(\"\\n############## Metricas MLP layer hidden 10 ,unidades 64 ##########\")\n",
    "print(classification_report(yntest,clf_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TVE</th>\n",
       "      <th>COVM</th>\n",
       "      <th>COVP</th>\n",
       "      <th>EDUM</th>\n",
       "      <th>EDUP</th>\n",
       "      <th>MTRAB</th>\n",
       "      <th>PTRAB</th>\n",
       "      <th>#PCONV</th>\n",
       "      <th>PHERMANO</th>\n",
       "      <th>TPOBLACION</th>\n",
       "      <th>...</th>\n",
       "      <th>ET</th>\n",
       "      <th>LAPTOP</th>\n",
       "      <th>INTERNET</th>\n",
       "      <th>DEPOR</th>\n",
       "      <th>RSENTI</th>\n",
       "      <th>P1-16</th>\n",
       "      <th>P2-16</th>\n",
       "      <th>P3-16</th>\n",
       "      <th>P4-16</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TVE  COVM  COVP  EDUM  EDUP  MTRAB  PTRAB  #PCONV  PHERMANO  TPOBLACION  \\\n",
       "0    0     0     0     0     0      0      0       9         0           0   \n",
       "1    1     1     0     1     1      1      0       3         3           0   \n",
       "2    1     1     0     2     0      0      0       5         3           0   \n",
       "3    0     1     0     2     2      0      0       4         1           0   \n",
       "4    0     1     1     1     1      1      0       2         4           0   \n",
       "\n",
       "  ...  ET  LAPTOP  INTERNET  DEPOR  RSENTI  P1-16  P2-16  P3-16  P4-16   C  \n",
       "0 ...   0       0         0      0       0    2.9    3.4    3.4    3.5  BS  \n",
       "1 ...   0       0         1      1       0    2.6    2.4    2.8    3.2  BS  \n",
       "2 ...   0       1         1      0       1    3.1    3.4    3.5    3.4  BS  \n",
       "3 ...   0       1         1      0       1    3.0    3.1    3.5    3.7  BS  \n",
       "4 ...   0       0         0      0       1    2.7    2.9    2.1    2.0  BS  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds_ = pd.read_csv('F8N4P.csv', sep=';', na_values=\"?\", decimal=',')# se carga el cojunto de datos csv\n",
    "ds_ = pd.read_csv('417.csv', sep=';', na_values=\"?\", decimal=',')# se carga el cojunto de datos csv\n",
    "\n",
    "#ds_ = pd.read_csv('F4NP17.csv', sep=';', na_values=\"?\", decimal=',')\n",
    "ds = ds_.dropna() # se elimina las filas/columnas con valores null\n",
    "# Convertir datos categoricos a numericos\n",
    "ds = ds.rename(columns = {ds.columns.values[21]:'C'}) # renombramos la ultima columna por \"C\" de clase\n",
    "#le = preprocessing.LabelEncoder() # Label encoder de sci-kit\n",
    "\n",
    "# Convertir datos categoricos a numericos\n",
    "tipos = ds.columns[0:21].to_series().groupby(ds.dtypes).groups\n",
    "ctext = tipos[np.dtype('object')]\n",
    "\n",
    "for c in ctext:\n",
    "     ds[c], _ = pd.factorize(ds[c])  \n",
    "\n",
    "\n",
    "\n",
    "##for c in ctext:\n",
    "  ##   VAL[c], _ = pd.factorize(VAL[c])  \n",
    "\n",
    "ds.C.value_counts()\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the boston dataset\n",
    "#data = datasets.load_boston()\n",
    "data.data=ds.drop('C', axis = 1)\n",
    "data.target=ds['C']\n",
    "# extract the predictors and target data.\n",
    "df = pd.DataFrame(data.data)\n",
    "y =  pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "#rf_reg = RandomForestRegressor()\n",
    "\n",
    "SVM = svm.SVC(kernel='linear',C=10, gamma=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from each Iteration:  [0.4782608695652174, 0.34782608695652173, 0.5652173913043478, 0.6086956521739131, 0.5217391304347826, 0.6956521739130435, 0.5217391304347826, 0.6086956521739131, 0.5652173913043478, 0.5652173913043478]\n",
      "Average K-Fold Score : 0.5478260869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Andres\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(10):\n",
    "    result = next(kf.split(df), None)\n",
    "    x_train = df.iloc[result[0]]\n",
    "    x_test = df.iloc[result[1]]\n",
    "    y_train = y.iloc[result[0]]\n",
    "    y_test = y.iloc[result[1]]\n",
    "    model = SVM.fit(x_train,y_train)\n",
    "    predictions = SVM.predict(x_test)\n",
    "    scores.append(model.score(x_test,y_test))\n",
    "print('Scores from each Iteration: ', scores)\n",
    "print('Average K-Fold Score :' , np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############## Accuracy SVM Lineal C=10, gamma=10 ##################\n",
      "0.5652173913043478\n",
      "\n",
      "############## Confusion SVM Lineal C=10, gamma=10 ################\n",
      "[[1 0 0]\n",
      " [0 6 5]\n",
      " [2 3 6]]\n",
      "\n",
      "############## Metricas SVM Lineal C=10, gamma=10 ##################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.33      1.00      0.50         1\n",
      "           B       0.67      0.55      0.60        11\n",
      "          BS       0.55      0.55      0.55        11\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        23\n",
      "   macro avg       0.52      0.70      0.55        23\n",
      "weighted avg       0.59      0.57      0.57        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n############## Accuracy SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(metrics.accuracy_score(y_test, predictions))\n",
    "print(\"\\n############## Confusion SVM Lineal C=10, gamma=10 ################\")\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "print(\"\\n############## Metricas SVM Lineal C=10, gamma=10 ##################\")\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the boston dataset\n",
    "#data = datasets.load_boston()\n",
    "data.data=ds.drop('C', axis = 1)\n",
    "data.target=ds['C']\n",
    "# extract the predictors and target data.\n",
    "#df = pd.DataFrame(data.data)\n",
    "#y =  pd.DataFrame(data.target)\n",
    " \n",
    "# extract the predictors and target data.\n",
    "predictors = data.data\n",
    "target = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((221, 21), (221,))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(predictors,target,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((176, 21), (45, 21), (176,), (45,))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(kernel='linear',C=10, gamma=10)\n",
    "model = SVM.fit(x_train,y_train)\n",
    "#rf_reg = RandomForestRegressor()\n",
    "#rf_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = rf_reg.predict(x_test)\n",
    "predictions = SVM.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "rsqure_score = model.score(x_train,y_train)\n",
    "print('R^2: {}'.format(rsqure_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-69de2db0bdea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_r2_scores_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_r2_scores_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean 5-Fold R Squared: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_r2_scores_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[1;32m---> 98\u001b[1;33m                                                  **self._kwargs)\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    535\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BS'"
     ]
    }
   ],
   "source": [
    "cv_r2_scores_rf = cross_val_score(model, predictors, target, cv=5,scoring='r2')\n",
    "print(cv_r2_scores_rf)\n",
    "print(\"Mean 5-Fold R Squared: {}\".format(np.mean(cv_r2_scores_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
